[{},{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"Statistical courses often taught way focuses underlying mathematics. approach may work well situations, particularly certain level theoretical knowledge required.However, comes using statistics research, theoretical approach can show shortcomings. large proportion post-graduate students receive training via Bioinformatics Training Facility strong mathematical background, means often struggle statistical topics taught undergraduate years. result, students tend follow statistical methods generally used journal within respective fields, without really understanding questioning suitability methods.materials resampling techniques part larger series statistical topics tries remedy . sessions delivered lecture-practical. 40-60 minute lecture underlying principles topic discussed, using examples practical applications. Discussion students encouraged asking questions - often asking opinions experiences, rather testing specific knowledge.approach encourages students engage think wider context .","code":""},{"path":"index.html","id":"assessment","chapter":"1 Overview","heading":"1.1 Assessment","text":"Assessment individual progress occurs ongoing formative assessment exercises, rather formal assessment. focus course much encouraging intuitive understanding underlying principals, rather mathematical one. , mathematical derivations (definitely pen paper calculations!).","code":""},{"path":"index.html","id":"evaluation","chapter":"1 Overview","heading":"1.2 Evaluation","text":"courses within Bioinformatics Training Facility get surveyed using surveymonkey surveys. exact content surveys large cover , surveys example gain insight participants engage course materials - course. also assess six months used knowledge ’ve gained research.less formal way assessing participants engage materials questions shared Q&document gets used course. Usually questions technical nature can tell participants focusing practical implementation coding. Although understandable, particularly early sessions, aim get participants ask questions deeper level, example asking reasons certain techniques used, volunteering alternative techniques also valid. shows participants thinking beyond ’re learning - often relating context research.second informal way gauging engagement materials number questions get course data. People often contact ask certain analysis technique ’ve tried research data correct, ask questions apply covered topics research. relevant learning outcome: using knowledge ’ve gained better research.","code":""},{"path":"index.html","id":"core-aims","chapter":"1 Overview","heading":"1.3 Core aims","text":"general learning outcomes sessions two-fold:intuitive understanding statistical techniquesBe able apply techniques appropriately research data, using R","code":""},{"path":"index.html","id":"index-datasets","chapter":"1 Overview","heading":"1.4 Datasets","text":"course uses various data sets. easiest way accessing creating R-project RStudio. download data folder right-clicking link Save …. Next unzip file copy working directory. data accessible via <working-directory-name>/data.practicals “tabs” show tidyverse. materials developed parallel using R syntax uses tidyverse, base R Python. purpose draft, examples base R included.rationale behind providing three distinct programmatic ways performing techniques encourage participants focus understanding statistics programming language. offering three different programming syntax participants can choose whatever syntax comfortable .materials also limit use colours ones colourblind friendly. encourage participants consider use colours creating figures (discussed throughout course)..panelset{--panel-tab-font-family: inherit;}","code":"## Warning: 'xaringanExtra::style_panelset' is deprecated.\n## Use 'style_panelset_tabs' instead.\n## See help(\"Deprecated\")"},{},{"path":"single-predictor-permutation-tests.html","id":"single-predictor-permutation-tests","chapter":"2 Single predictor permutation tests","heading":"2 Single predictor permutation tests","text":"","code":""},{"path":"single-predictor-permutation-tests.html","id":"objectives","chapter":"2 Single predictor permutation tests","heading":"2.1 Objectives","text":"ObjectivesUnderstand resampling techniques work RBe able carry permutation techniques single predictorsBe able define statistic permuteUnderstand advantages limitations permutation techniques","code":""},{"path":"single-predictor-permutation-tests.html","id":"introduction","chapter":"2 Single predictor permutation tests","heading":"2.2 Introduction","text":"Core statistics sessions covered lot traditional statistics. became apparent throughout sessions, underlying principles lot statistical tests actually quite similar (course makes life lot easier!).One main topics discussed (length), need checking assumptions. multiple assumptions underlying vast majority statistical tests , unfortunately, assumptions often ignored, forgotten otherwise dealt .example, assumption parent distribution often normally distributed variance (spread) different groups less equal. Also, statistic often tested mean. assumptions met, life great! Actually, find situation, can probably stop reading now, grab cup tea enjoy day.…data unfortunately often kind us. data looks like :Oh dear. fit perfect world, ? data definitely normally distributed. also unlikely care means either. , data appear bi-modal ’re comparing control treatment ’re likely care difference means two peaks two groups.presents us bit issue, fit within statistical tests ’ve covered. honest, actually obvious statistical tests use . , ’s statistician supposed case?Well, like discussed lecture, null hypothesis indicates difference means, actually swap data points impunity! , randomly getting data points control group swapping data points treatment group , average, effect difference means - null hypothesis true!illustrate , ’re going run example two groups mice (poor things), ’ve recorded weight based certain diet. case actually interested difference mean weight, beauty technique can define statistic ’d like. course ’d still justify meaningful statistic case , looked difference means peaks, shouldn’t much problem.","code":""},{"path":"single-predictor-permutation-tests.html","id":"libraries-and-functions","chapter":"2 Single predictor permutation tests","heading":"2.3 Libraries and functions","text":"tidyverse","code":""},{"path":"single-predictor-permutation-tests.html","id":"purpose-and-aim","chapter":"2 Single predictor permutation tests","heading":"2.4 Purpose and aim","text":"wish test difference two groups case assumptions two-sample t-test just aren’t met, two-sample permutation test procedure appropriate. also appropriate even assumptions t-test met, case, easier just t-test.One additional benefits permutation test aren’t just restricted testing hypotheses means two groups. can test hypotheses absolutely anything want! , see ranges two groups differed significantly etc.","code":""},{"path":"single-predictor-permutation-tests.html","id":"data-and-hypotheses","chapter":"2 Single predictor permutation tests","heading":"2.5 Data and hypotheses","text":"Let’s consider experimental data set measured weights two groups 12 female mice (24 mice total). One group mice given perfectly normal diet (control) group mice given high fat diet several months. want test whether difference mean weight two groups. still need specify hypotheses:\\(H_0\\): difference means two groups\\(H_1\\): difference means two groups","code":""},{"path":"single-predictor-permutation-tests.html","id":"load-and-visualise-the-data","chapter":"2 Single predictor permutation tests","heading":"2.5.1 Load and visualise the data","text":"First load data, visualise .tidyverseIt looks mice fed high fat diet greater weight control (hardly surprising!). look bit closely calculate difference mean weight two groups:Let’s store value object called mice_diff.Right, difference two group means 3.02, hoorah! difference lot? unusual/big/statistically significant?Specifically, likely get difference big difference two groups? Let’s find !","code":"\n# load the data\nmice <- read_csv(\"data/mice.csv\")\n\n# view the data\nmice## # A tibble: 24 × 2\n##    diet    weight\n##    <chr>    <dbl>\n##  1 control   21.5\n##  2 control   28.1\n##  3 control   24.0\n##  4 control   23.4\n##  5 control   23.7\n##  6 control   19.8\n##  7 control   28.4\n##  8 control   21.0\n##  9 control   22.5\n## 10 control   20.1\n## # … with 14 more rows\nggplot(mice, aes(x = diet, y = weight)) +\n  geom_boxplot()\n# determine mean weight per group\nmice %>% \n  group_by(diet) %>%                         # split data by diet\n  summarise(mean_weight = mean(weight)) %>%  # calculate mean weight per group\n  ungroup() %>%                              # remove the grouping\n  pull(mean_weight) %>%                      # extract group values\n  diff()                                     # calculate the difference## [1] 3.020833"},{"path":"single-predictor-permutation-tests.html","id":"permutation-test-theory","chapter":"2 Single predictor permutation tests","heading":"2.6 Permutation Test Theory","text":"key idea behind permutation techniques null hypothesis true, difference two groups switch mice one group next wouldn’t change difference groups much. hand actually difference groups (one group much higher weights ), switch mice groups average two groups leading smaller difference group means., shuffle mice weights around lots lots times, calculating difference group means time. done shuffling hundreds thousands times, loads possible values difference two group means. stage can look actual difference (one calculated original data) see compares simulated differences.\ncan calculate many simulated differences bigger real difference proportion exactly p-value ’re looking !\nLet look carry practice.tidyversebase RtidyverseTo get better sense reliable p-value might , repeat whole process many times obtain resulting p-values.One way getting p-value single iteration follows:want repeat iterations many times can wrap whole workflow used obtain p-value within replicate() function tell many times want repeat . repeat whole process 100 times:might get warning reporting p-value zero. depends number reps chosen generate() function. ’s low , due simulation-based nature package observed statistic extreme test statistic generated form null hypothesis. happens, approximate p-value zero. Ending warning, true p-value zero impossible.","code":"\nset.seed(123)\n\nmice_resample <- mice %>% \n  specify(weight ~ diet) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(\"diff in means\", order = c(\"control\", \"highfat\"))\n\nmice_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = mice_diff, direction = \"two-sided\")\nset.seed(123)\nreps<-1000\nsim_diff<-numeric(reps)\nfor(i in 1:reps){\n  new_dat<-mice\n  new_dat$diet<-sample(new_dat$diet)\n  new_means <- aggregate(weight ~ diet , new_dat , mean)$weight\n  new_diff <- diff(new_means)\n  \n  sim_diff[i]<-new_diff  \n}\nhist(sim_diff , breaks = 30 , col=\"red\")\nabline(v = mice_diff , col=\"black\" , lwd=2)\n# get a two-tailed p-value\np_value <- mice_resample %>%\n  get_p_value(obs_stat = mice_diff, direction = \"two-sided\")\n\np_value## # A tibble: 1 × 1\n##   p_value\n##     <dbl>\n## 1   0.074\n# remove the set.seed()\n# otherwise we get the same result 100 times\nset.seed(NULL)\n\nresample_replicates <- replicate(100, mice %>% \n  specify(weight ~ diet) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(\"diff in means\", order = c(\"control\", \"highfat\")) %>% \n  get_p_value(obs_stat = mice_diff, direction = \"two-sided\") %>% \n  pull()) %>% \n  as_tibble() %>% \n  mutate(n_rep = 1:n(),\n         p_value = value) %>% \n  select(-value)\n\nggplot(resample_replicates, aes(x = p_value)) +\n  geom_histogram(bins = 10)"},{"path":"single-predictor-permutation-tests.html","id":"exercise-rats-on-a-wheel","chapter":"2 Single predictor permutation tests","heading":"2.7 Exercise: Rats on a wheel","text":"Exercise 2.1  data set data/rats.csv contains information length time 24 rats able stay balanced rotating wheel. 12 rats assigned control group 12 given dose centrally acting muscle relaxant. animals placed rotating cylinder length time rat remained cylinder measured, maximum 300 seconds. data set contains two variables time group.\nWhilst explore differences means two groups, case alternative statistic presents . look data notice control group 12 rats manage stay roller maximum 300 seconds, whereas treated group 5 12 fall earlier.exercise, instead calculating mean length time group, calculate proportion rats make 300s group find difference. statistic.Use permutation test decide whether proportion rats survive group.tidyverse\nlook stat options calculate() functiontidyverseAs always, let’s first load visualise data:lot overlap values (many rats manage stay wheel entire 300s), need jitter data bit.’re interested proportion rats make full 300s. , let’s calculate :, means proportion rats make full-time follows:Now, question , difference proportion likely ? check , resample data see likely proportional difference observe .answer : likely. One thing keep mind ’ve resampled thousand times . ’s really fair, since thousand different options possible due low sample size. However, just means responses occur often. able calculate exactly, without using resampling, bit headache. Importantly, really use technique much samples, ’s good illustration can use technique analyse different statistics.put number , can get p-value like :base R","code":"\nrats <- read_csv(\"data/rats.csv\")\n\nrats## # A tibble: 24 × 2\n##     time group  \n##    <dbl> <chr>  \n##  1   300 control\n##  2   300 control\n##  3   300 control\n##  4   300 control\n##  5   300 control\n##  6   300 control\n##  7   300 control\n##  8   300 control\n##  9   300 control\n## 10   300 control\n## # … with 14 more rows\nrats %>% \n  ggplot(aes(x = group, y = time)) +\n  geom_jitter(width = 0.1)\nrats <- rats %>% \n  group_by(group) %>% \n  mutate(full_time = time == 300,\n         full_time = as.character(full_time))\nfull_time_control = 12/12\nfull_time_treatment = 7/12\n\nrats_diff <- full_time_control - full_time_treatment\nset.seed(123)\nrats_resample <- rats %>% \n  specify(full_time ~ group, success = \"TRUE\") %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  calculate(\"diff in props\", order = c(\"control\", \"treatment\"))\n\nrats_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = rats_diff, direction = \"two-sided\")\n# get a two-tailed p-value\np_value <- rats_resample %>%\n  get_p_value(obs_stat = rats_diff, direction = \"two-sided\")\n\np_value## # A tibble: 1 × 1\n##   p_value\n##     <dbl>\n## 1   0.038\nset.seed(123)\nrats_r <- read.csv(\"data/rats.csv\")\n\nunstRats<-unstack(rats_r)\n\npropControl <- length(\n  which(unstRats$control==300)) / length(unstRats$control)\n\npropTreatment <- length(\n  which(unstRats$treatment==300)) / length(unstRats$treatment)\n\nratDiff <- propControl - propTreatment\n\nnReps <- 1000\nsimRat<-numeric(nReps)\n\nfor(i in 1:nReps){\n  \n  newdat <- rats_r\n  newdat$group <- sample(newdat$group)\n  \n  newUnstRats <- unstack(newdat)\n  \n  newPropControl <- length(\n    which(newUnstRats$control==300))/length(newUnstRats$control)\n  \n  newPropTreatment <- length(\n    which(newUnstRats$treatment==300))/length(newUnstRats$treatment)\n  \n  newDiff <- newPropControl - newPropTreatment\n  \n  simRat[i] <- newDiff\n}\n\nhist(simRat, breaks = 30, col='red' , main=\"\" , xlab=\"Simulated Differences\")\nabline(v = ratDiff, col = \"black\", lwd = 2)\nabline(v = -ratDiff, col = \"black\", lwd = 2)"},{"path":"single-predictor-permutation-tests.html","id":"resampling-based-on-a-linear-regression","chapter":"2 Single predictor permutation tests","heading":"2.8 Resampling based on a linear regression","text":"far ’ve seen two examples can use permutation techniques look data: looking difference means (mice---diet example) comparing difference proportion (rats---wheel exercise).might noticed code little difference approach, good! ’re going adjust code slightly, can similar resampling exercise using linear model. look , ’re using data set penguins.tidyverseThe penguins data set part library called palmerpenguins, ’ll install load:Let’s attach data remove missing values. ’re also filter data one type penguin, just make analysis bit easier follow.can see 8 variables. ’ll come back later sessions, now ’re focusing 3:species type penguinflipper_length_mm length flipper mmbill_length_mm length bill mmTo practice, ’ll look relationship flipper length bill length, comparing two species selected.tidyverseLooking data, seems overall positive relationship flipper length bill length. relationship species-dependent, doesn’t seem much interaction going , since lines best fit pretty much parallel.Let’s look models resampling perspective.tidyverseFirst, specify model. ’re creating additive model, bill_length_mm depends flipper_length_mm species:aside, Power analysis session Core statistics looked model evaluation. something similar see interaction flipper_length_mm species:can see AIC value gets tiny bit worse drop interaction term. means species contributing model, although tiny bit.Next, fit models resamples data set:Lastly, can get p-value, comparing likely observed_fit based resampled fits simulated:, ’re likely get warning stating result approximation based number reps chosen. ’s unlikely true p-value zero.based , seems unlikely ’d get coefficients linear model data described best horizontal line (pretty obvious looking data!).Alternatively, can view plotting simulated null distributions placing coefficient values observed linear model top:can also compare looking confidence intervals simulated coefficients. ’re showing 95% confidence intervals, comparing observed values coefficients (.e. ones get fitting model actual data)., interpret results? Well, coefficients linear model fitted actual data miles away coefficients obtained simulated data. Remember, simulated data permuted (randomly shuffled) bill_length_mm values, refitted linear model calculated corresponding coefficients.fine relationship bill length, flipper length species. reshuffling data effect. clearly relationship variables, can see plotted data line best fit.Just satisfy curiosity (’re still point surely must curious!), can check normal approach, fit linear model perform ANOVA:Note ’ve included interaction flipper length species (flipper_length_mm:species) , consistent AIC result, ’s much data suggest interaction two variables.Finally, ANOVA confirms ’re seeing permutation test: data described best horizontal line, linear model able account good proportion variance data (adjusted R-squared value 0.37).","code":"\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndata(\"penguins\")\n\npenguins <- penguins %>%\n  filter(species != \"Adelie\") %>% \n  drop_na()\n\npenguins## # A tibble: 187 × 8\n##    species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##    <fct>   <fct>           <dbl>         <dbl>             <int>       <int>\n##  1 Gentoo  Biscoe           46.1          13.2               211        4500\n##  2 Gentoo  Biscoe           50            16.3               230        5700\n##  3 Gentoo  Biscoe           48.7          14.1               210        4450\n##  4 Gentoo  Biscoe           50            15.2               218        5700\n##  5 Gentoo  Biscoe           47.6          14.5               215        5400\n##  6 Gentoo  Biscoe           46.5          13.5               210        4550\n##  7 Gentoo  Biscoe           45.4          14.6               211        4800\n##  8 Gentoo  Biscoe           46.7          15.3               219        5200\n##  9 Gentoo  Biscoe           43.3          13.4               209        4400\n## 10 Gentoo  Biscoe           46.8          15.4               215        5150\n## # … with 177 more rows, and 2 more variables: sex <fct>, year <int>\nggplot(penguins, aes(x = flipper_length_mm,\n                     y = bill_length_mm,\n                     colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\nobserved_fit <- penguins %>% \n  specify(bill_length_mm ~ flipper_length_mm + species) %>% \n  fit()\n# define the model\nlm_penguins <- lm(bill_length_mm ~ flipper_length_mm * species,\n                  data = penguins)\n\n# have a look at the coefficients\nsummary(lm_penguins)## \n## Call:\n## lm(formula = bill_length_mm ~ flipper_length_mm * species, data = penguins)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -6.6977 -1.6578 -0.0014  1.4064 12.4394 \n## \n## Coefficients:\n##                                  Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                       5.59338    8.65665   0.646   0.5190    \n## flipper_length_mm                 0.22081    0.04418   4.998 1.35e-06 ***\n## speciesGentoo                   -26.08126   11.67592  -2.234   0.0267 *  \n## flipper_length_mm:speciesGentoo   0.09247    0.05702   1.622   0.1066    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 2.579 on 183 degrees of freedom\n## Multiple R-squared:  0.3774, Adjusted R-squared:  0.3672 \n## F-statistic: 36.97 on 3 and 183 DF,  p-value: < 2.2e-16\n# do a backwards stepwise elimination\nstats::step(lm_penguins)## Start:  AIC=358.28\n## bill_length_mm ~ flipper_length_mm * species\n## \n##                             Df Sum of Sq    RSS    AIC\n## <none>                                   1217.1 358.28\n## - flipper_length_mm:species  1    17.491 1234.6 358.95## \n## Call:\n## lm(formula = bill_length_mm ~ flipper_length_mm * species, data = penguins)\n## \n## Coefficients:\n##                     (Intercept)                flipper_length_mm  \n##                         5.59338                          0.22081  \n##                   speciesGentoo  flipper_length_mm:speciesGentoo  \n##                       -26.08126                          0.09247\npenguins_resample <- penguins %>% \n  specify(bill_length_mm ~ flipper_length_mm + species) %>% \n  hypothesise(null = \"independence\") %>% \n  generate(reps = 1000, type = \"permute\") %>% \n  fit()\nget_p_value(penguins_resample, obs_stat = observed_fit, direction = \"two-sided\")## # A tibble: 3 × 2\n##   term              p_value\n##   <chr>               <dbl>\n## 1 flipper_length_mm       0\n## 2 intercept               0\n## 3 speciesGentoo           0\npenguins_resample %>% \n  visualise() +\n  shade_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n# generate the 95% confidence intervals\nget_confidence_interval(\n  penguins_resample, \n  point_estimate = observed_fit, \n  level = .95\n)## # A tibble: 3 × 3\n##   term              lower_ci upper_ci\n##   <chr>                <dbl>    <dbl>\n## 1 flipper_length_mm  -0.0703   0.0753\n## 2 intercept          33.1     61.7   \n## 3 speciesGentoo      -1.91     1.78\n# display the coefficients of the observed linear model\nobserved_fit## # A tibble: 3 × 2\n##   term              estimate\n##   <chr>                <dbl>\n## 1 intercept           -5.28 \n## 2 flipper_length_mm    0.276\n## 3 speciesGentoo       -7.18\n# fit the model\nlm_penguins <- lm(bill_length_mm ~ flipper_length_mm * species,\n                  data = penguins)\n\n# check assumptions (which all look fine)\nlibrary(ggResidpanel)\nlm_penguins %>% \n  resid_panel(c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n              smoother = TRUE)\nanova(lm_penguins)## Analysis of Variance Table\n## \n## Response: bill_length_mm\n##                            Df  Sum Sq Mean Sq  F value    Pr(>F)    \n## flipper_length_mm           1   49.33   49.33   7.4174  0.007085 ** \n## species                     1  670.92  670.92 100.8749 < 2.2e-16 ***\n## flipper_length_mm:species   1   17.49   17.49   2.6298  0.106594    \n## Residuals                 183 1217.14    6.65                       \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"single-predictor-permutation-tests.html","id":"key-points","chapter":"2 Single predictor permutation tests","heading":"2.9 Key points","text":"Permutation techniques applicable regardless underlying distributionThey allow test non-standard metricsThey require sufficient dataWe can use workflow infer package, part tidymodels perform permutations dataWe specify() model, use hypothesise() define null hypothesis, generate() reshuffled data calculate() statistic interestWe can reiterate workflow obtain distribution p-valuesThis distribution p-values gives indication reliable statistical result ","code":""}]
